{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ylfoo/ERA2036/blob/main/Lab/Learn_Classification_thru_Steel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit to Law Yi Yang"
      ],
      "metadata": {
        "id": "SGyoTOGSgI2b"
      },
      "id": "SGyoTOGSgI2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbeccaed",
      "metadata": {
        "id": "dbeccaed",
        "outputId": "6ac029bb-0559-4739-86c5-b53d2241a7f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(159, 7)\n",
            "    Species  Weight  Length1  Length2  Length3   Height   Width\n",
            "17    Bream   700.0     30.4     33.0     38.5  14.9380  5.1975\n",
            "63   Parkki    90.0     16.3     17.7     19.8   7.4052  2.6730\n",
            "51    Roach   180.0     23.6     25.2     27.9   7.0866  3.9060\n",
            "16    Bream   700.0     30.4     33.0     38.3  14.8604  5.2854\n",
            "99    Perch   180.0     23.0     25.0     26.5   6.4395  3.6835\n",
            "114   Perch   700.0     34.5     37.0     39.4  10.8350  6.2646\n",
            "154   Smelt    12.2     11.5     12.2     13.4   2.0904  1.3936\n",
            "123   Perch  1100.0     39.0     42.0     44.6  12.8002  6.8684\n",
            "152   Smelt     9.9     11.3     11.8     13.1   2.2139  1.1659\n",
            "132    Pike   430.0     35.5     38.0     40.5   7.2900  4.5765\n"
          ]
        }
      ],
      "source": [
        "# Classification model to predict the fish species\n",
        "# Load modules and packages\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split as split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/wooihaw/datasets/main/fish.csv')"
      ],
      "metadata": {
        "id": "nIk5Wa0Bg1__"
      },
      "id": "nIk5Wa0Bg1__",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension of dataset\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "kNcaSQRXg9Qw"
      },
      "id": "kNcaSQRXg9Qw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preview 10 lines of data\n",
        "print(df.sample(10))"
      ],
      "metadata": {
        "id": "CglXJlOdg_gq"
      },
      "id": "CglXJlOdg_gq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "765090b3",
      "metadata": {
        "id": "765090b3",
        "outputId": "d76a1eb5-e262-4cfc-d869-9b5cc65e1fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Weight     Length1     Length2     Length3      Height       Width\n",
            "count   159.000000  159.000000  159.000000  159.000000  159.000000  159.000000\n",
            "mean    398.326415   26.247170   28.415723   31.227044    8.970994    4.417486\n",
            "std     357.978317    9.996441   10.716328   11.610246    4.286208    1.685804\n",
            "min       0.000000    7.500000    8.400000    8.800000    1.728400    1.047600\n",
            "25%     120.000000   19.050000   21.000000   23.150000    5.944800    3.385650\n",
            "50%     273.000000   25.200000   27.300000   29.400000    7.786000    4.248500\n",
            "75%     650.000000   32.700000   35.500000   39.650000   12.365900    5.584500\n",
            "max    1650.000000   59.000000   63.400000   68.000000   18.957000    8.142000\n",
            "knn accuracy: 0.525\n",
            "dtc accuracy: 0.475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
          ]
        }
      ],
      "source": [
        "# Descriptive statistics\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "y = df.values[:, 0]\n",
        "del df[\"Species\"]\n",
        "X = df.values\n",
        "X_train, X_test, y_train, y_test = split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "q7tVaO-GhP3E"
      },
      "id": "q7tVaO-GhP3E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate a k-NN model with k=1\n",
        "knn = KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train)\n",
        "print(f\"knn accuracy: {knn.score(X_test, y_test)}\")"
      ],
      "metadata": {
        "id": "32NzxbQ3hwdS"
      },
      "id": "32NzxbQ3hwdS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate a decision tree model with max_depth=1\n",
        "dtc = DecisionTreeClassifier(random_state=42, max_depth=1).fit(X_train, y_train)\n",
        "print(f\"dtc accuracy: {dtc.score(X_test, y_test)}\")"
      ],
      "metadata": {
        "id": "XlM8hEuKh1_a"
      },
      "id": "XlM8hEuKh1_a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52270673",
      "metadata": {
        "id": "52270673",
        "outputId": "83933066-86a8-47ed-d486-86ab318c0461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensions of the dataset: (159, 6)\n",
            "Dimensions of the training set (X_train): (119, 6)\n",
            "Dimensions of the testing set (X_test): (40, 6)\n"
          ]
        }
      ],
      "source": [
        "print(\"Dimensions of the dataset:\", df.shape)\n",
        "print(\"Dimensions of the training set (X_train):\", X_train.shape)\n",
        "print(\"Dimensions of the testing set (X_test):\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a960a91c",
      "metadata": {
        "id": "a960a91c",
        "outputId": "c5d56667-9cde-45ed-e57b-c732cf6faacb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features in the dataset: 6\n"
          ]
        }
      ],
      "source": [
        "num_features = X_train.shape[1]\n",
        "print(\"Number of features in the dataset:\", num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f38417",
      "metadata": {
        "id": "15f38417",
        "outputId": "f6c2da71-bf2e-4a0b-f6cc-bde7417d47bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of data samples in the training set: 119\n",
            "Number of data samples in the testing set: 40\n"
          ]
        }
      ],
      "source": [
        "num_samples_train = X_train.shape[0]\n",
        "num_samples_test = X_test.shape[0]\n",
        "print(\"Number of data samples in the training set:\", num_samples_train)\n",
        "print(\"Number of data samples in the testing set:\", num_samples_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "696fa7f4",
      "metadata": {
        "id": "696fa7f4",
        "outputId": "ecc23c0b-6b10-4357-f8fc-e34a72c85864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-NN Performance:\n",
            "k=3, accuracy: 0.475\n",
            "k=5, accuracy: 0.6\n",
            "k=7, accuracy: 0.575\n",
            "k=9, accuracy: 0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
            "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
          ]
        }
      ],
      "source": [
        "k_values = [3, 5, 7, 9]\n",
        "knn_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k).fit(X_train, y_train)\n",
        "    knn_score = knn.score(X_test, y_test)\n",
        "    knn_scores.append((k, knn_score))\n",
        "\n",
        "print(\"K-NN Performance:\")\n",
        "for k, score in knn_scores:\n",
        "    print(f\"k={k}, accuracy: {score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99d8efb",
      "metadata": {
        "id": "a99d8efb",
        "outputId": "fd7128d1-fe58-4cf0-9013-231c4b2f245c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Performance:\n",
            "max_depth=2, accuracy: 0.675\n",
            "max_depth=3, accuracy: 0.7\n",
            "max_depth=4, accuracy: 0.7\n",
            "max_depth=5, accuracy: 0.725\n",
            "max_depth=6, accuracy: 0.625\n",
            "max_depth=7, accuracy: 0.75\n",
            "max_depth=8, accuracy: 0.775\n",
            "max_depth=9, accuracy: 0.7\n",
            "max_depth=10, accuracy: 0.725\n"
          ]
        }
      ],
      "source": [
        "max_depth_values = list(range(2, 11))\n",
        "dtc_scores = []\n",
        "\n",
        "for max_depth in max_depth_values:\n",
        "    dtc = DecisionTreeClassifier(random_state=42, max_depth=max_depth).fit(X_train, y_train)\n",
        "    dtc_score = dtc.score(X_test, y_test)\n",
        "    dtc_scores.append((max_depth, dtc_score))\n",
        "\n",
        "print(\"Decision Tree Performance:\")\n",
        "for max_depth, score in dtc_scores:\n",
        "    print(f\"max_depth={max_depth}, accuracy: {score}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb557506",
      "metadata": {
        "id": "eb557506"
      },
      "source": [
        "Between these two models, Decision Tree is more suitable for this dataset and max_depth = 8 is the optimum value for the hyperparameter."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}